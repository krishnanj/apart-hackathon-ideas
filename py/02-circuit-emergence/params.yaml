p: 97
train_frac: 0.8
seed: 42
widths: [16, 32, 64, 128, 256]
depth: 5  # Keep the deeper model
lr: 0.001
steps: 5000
concept: "x_equals_y"

# Enable synthetic functions
use_synthetic: true
use_composite: true  # Enable composite functions f(g(x))

# Synthetic function parameters
func_type: "trigonometric"  # Keep trigonometric for complexity
complexity: 3
input_range: [-5, 5]
n_samples: 1000

# Composite function parameters
inner_func: "poly"  # Keep polynomial
outer_func: "relu"  # Change to ReLU tree (more complex)
inner_complexity: 4  # Increase polynomial degree
outer_complexity: 5  # Increase ReLU depth

# Probe configuration
probe_mode: "all"  # "all", "single", or "custom"
probe_type: "linear"  # linear, tree, svm, mlp (used when probe_mode is "single")
custom_probes: ["linear", "tree", "svm"]  # used when probe_mode is "custom"

# Symmetry test parameters
symmetry_test_samples: 500

# Complexity sweep parameters
complexity_sweep: true
complexity_function: "trigonometric"
complexity_range: [1, 2, 4, 8, 16, 32]
emergence_threshold: 0.8
phase_detection: true
complexity_widths: [16, 32, 64]  # Smaller widths
complexity_depth: 3  # Fewer layers